import requests
from bs4 import BeautifulSoup
import re
from urllib.parse import quote
import csv
from time import sleep


def get_social_links(url):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –≤—Å–µ —Å–æ—Ü–∏–∞–ª—å–Ω—ã–µ —Å—Å—ã–ª–∫–∏ —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
    try:
        headers = {
            'User-Agent':
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        response = requests.get(url, headers=headers, timeout=15)
        soup = BeautifulSoup(response.text, 'html.parser')

        social_links = []
        for a in soup.find_all('a', href=True):
            href = a['href'].lower()
            if 'linkedin.com/company' in href:
                if not href.startswith('http'):
                    href = f"https://www.linkedin.com{href}"
                social_links.append(href)

        return list(set(social_links))

    except Exception as e:
        print(f"  [!] –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ {url}: {str(e)}")
        return []


def search_google(company_name):
    """–ü–æ–∏—Å–∫ —á–µ—Ä–µ–∑ Google (–∏–º–∏—Ç–∞—Ü–∏—è)"""
    try:
        search_query = f"{company_name} site:linkedin.com/company"
        google_url = f"https://www.google.com/search?q={quote(search_query)}"

        headers = {
            'User-Agent':
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        response = requests.get(google_url, headers=headers, timeout=15)

        linkedin_links = re.findall(
            r'https?://[a-z]+\.linkedin\.com/company/[^\s"\'>]+',
            response.text)
        return linkedin_links[0] if linkedin_links else None

    except Exception as e:
        print(f"  [!] –û—à–∏–±–∫–∞ Google: {e}")
        return None


def find_linkedin(company_name, website_url, cryptorank_url):
    """–ü–æ–∏—Å–∫ LinkedIn —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º–∏"""
    print(f"\nüîç –ü–æ–∏—Å–∫ LinkedIn –¥–ª—è {company_name}")

    # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–≥–æ —Å–∞–π—Ç–∞
    print("  [1] –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–≥–æ —Å–∞–π—Ç–∞...")
    website_links = get_social_links(website_url)
    if website_links:
        print(f"  [+] –ù–∞–π–¥–µ–Ω –Ω–∞ —Å–∞–π—Ç–µ: {website_links[0]}")
        return website_links[0]

    # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ Cryptorank
    print("  [2] –ü—Ä–æ–≤–µ—Ä–∫–∞ Cryptorank...")
    cryptorank_links = get_social_links(cryptorank_url)
    if cryptorank_links:
        print(f"  [+] –ù–∞–π–¥–µ–Ω –Ω–∞ Cryptorank: {cryptorank_links[0]}")
        return cryptorank_links[0]

    # 3. –ü–æ–∏—Å–∫ —á–µ—Ä–µ–∑ Google
    print("  [3] –ü–æ–∏—Å–∫ —á–µ—Ä–µ–∑ Google...")
    google_result = search_google(company_name)
    if google_result:
        print(f"  [+] –ù–∞–π–¥–µ–Ω —á–µ—Ä–µ–∑ Google: {google_result}")
        return google_result

    # 4. –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –Ω–∞–∑–≤–∞–Ω–∏—è
    alt_names = [
        company_name.split('(')[0].strip(),
        company_name.split()[0],
        re.sub(r'[^\w\s]', '', company_name)
    ]

    for name in set(alt_names):
        if name != company_name:
            print(f"  [4] –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–≥–æ –Ω–∞–∑–≤–∞–Ω–∏—è: {name}")
            google_result = search_google(name)
            if google_result:
                print(
                    f"  [+] –ù–∞–π–¥–µ–Ω –ø–æ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–º—É –Ω–∞–∑–≤–∞–Ω–∏—é: {google_result}"
                )
                return google_result

    print("  [-] LinkedIn –Ω–µ –Ω–∞–π–¥–µ–Ω")
    return "Not Found"


def process_file(input_file, output_file):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ñ–∞–π–ª –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã"""
    with open(input_file, 'r', encoding='utf-8') as infile, \
         open(output_file, 'w', encoding='utf-8', newline='') as outfile:

        reader = csv.reader(infile, delimiter='\t')
        writer = csv.writer(outfile, delimiter='\t')

        writer.writerow(['Company Name', 'Website', 'Cryptorank', 'LinkedIn'])

        for row in reader:
            if len(row) < 3:
                continue

            company = row[0].strip()
            website = row[1].strip()
            cryptorank = row[2].strip()

            linkedin = find_linkedin(company, website, cryptorank)
            writer.writerow([company, website, cryptorank, linkedin])

            sleep(1)  # –ó–∞—â–∏—Ç–∞ –æ—Ç –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏


if __name__ == "__main__":
    input_file = "companies.txt"
    output_file = "companies_with_linkedin.tsv"

    print("üöÄ –ù–∞—á–∞–ª –æ–±—Ä–∞–±–æ—Ç–∫—É –∫–æ–º–ø–∞–Ω–∏–π...")
    process_file(input_file, output_file)
    print(f"\n‚úÖ –ì–æ—Ç–æ–≤–æ! –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ {output_file}")
